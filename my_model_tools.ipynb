{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from enum import Enum\n",
    "from typing import NamedTuple\n",
    "import functools\n",
    "\n",
    "from sklearn.linear_model import HuberRegressor, LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import zscore\n",
    "from scipy.linalg import inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions & Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions that compute some model evaluation metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Absolute Error (MAE)\n",
    "def mae(y, y_pred):\n",
    "    return np.mean(np.abs(np.subtract(y, y_pred)))\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "def mse(y, y_pred):\n",
    "    return np.mean(np.square(np.subtract(y, y_pred)))\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(mse(y, y_pred))\n",
    "\n",
    "# Residual Sum of Squares (RSS)\n",
    "def rss(y, y_pred):\n",
    "    return np.sum(np.square(np.subtract(y, y_pred)))\n",
    "\n",
    "# Total Sum of Squares\n",
    "def tss(y):\n",
    "    return rss(y, np.mean(y))\n",
    "\n",
    "# R2 Score\n",
    "def r2score(y, y_pred):\n",
    "    return 1 - rss(y, y_pred) / tss(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the inverse function of the logarithmic in base 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.log10 inverse function\n",
    "log10_inverse_fn = functools.partial(np.power, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes, Enums and NamedTuple to build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VariableType Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four types of variable: continous, discrete, ordinal and nominal.  \n",
    "We represent them with a `VariableType` Enum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Type\n",
    "class VariableType(Enum):\n",
    "    CONTINUOUS = 1\n",
    "    DISCRETE = 2\n",
    "    ORDINAL = 3\n",
    "    NOMINAL = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable NamedTuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variable/feature/predictor can be represented by four properties: name, variable type, a mapping/encoding and a transformation function.  \n",
    "Mapping/encoding is required for ordinal and nominal variables.  \n",
    "Transformation function can be used to transform a continous variable (example: logarithmic transformation of the Lot Area)\n",
    "\n",
    "We define a `Variable` **immutable** *structure* with the help of NamedTuple (immutable and more friendly than tuple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable NameTuple (We want an immutable structure more friendly than tuples)\n",
    "class Variable(NamedTuple):\n",
    "    name: str\n",
    "    type: VariableType\n",
    "    mapping: dict = None\n",
    "    fn: fn = None\n",
    "    \n",
    "    # return a new variable with a different name\n",
    "    def set_name(self, new_name):\n",
    "        return Variable(new_name, self.type, self.mapping, self.fn)\n",
    "    \n",
    "    # return a new variable with a different type\n",
    "    def set_type(self, new_type):\n",
    "        return Variable(self.name, new_type, self.mapping, self,fn)\n",
    "    \n",
    "    # return a new variable with a different transformation function\n",
    "    def set_function(self, new_fn):\n",
    "        return Variable(self.name, self.type, self.mapping, new_fn)\n",
    "    \n",
    "    # return a new variable with a different mapping (merged or overriden)\n",
    "    def set_mapping(self, new_mapping, merge=True):\n",
    "        if merge:\n",
    "            new_mapping = {**self.mapping, **new_mapping}\n",
    "        return Variable(self.name, self.type, new_mapping, self.fn)\n",
    "    \n",
    "    # return True if the mapping allow to map all the data \n",
    "    def check_mapping(self, serie):\n",
    "        for key in serie.unique():\n",
    "            if key not in self.mapping:\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ModelDataFrameBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is the class that do the job of preparing the data according to our wish:\n",
    "\n",
    "1. Creating a `ModelDataFrameBuilder` object\n",
    "2. Call its `prepare()` method by providing :\n",
    "    * the source dataframe (will not be altered by the preparation process)\n",
    "    * the list of variables (as Variable objects) to prepare\n",
    "3. Get the prepared data by calling the `data()` method\n",
    "\n",
    "**Note:**  \n",
    "All transformations applied during the preparation have no side effects on our source data. We can prepare different data set with different variables and mapping rules without risk to encounter re-entrance issues.\n",
    "\n",
    "The class also provide some post processing preparation methods:\n",
    "\n",
    "* `create_interaction_with_nominal_variable()` that allow to multiply the dummy variables by the value of a continuous variable  \n",
    "(I tried different things like creating an interaction between the lot area and the neighborhood variable)\n",
    "* `merge_dummy_variables()` to merge the `condition 1 & 2` & `exterior 1st & 2nd` dummy variables\n",
    "* `normalize()` that allow to standardize/normalize the predictors (can pass an exclusion list if needed and the method used z-score|center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelDataFrameBuilder:\n",
    "    def __init__(self):\n",
    "        self.model_data = pd.DataFrame()\n",
    "        self.prepared_variables = []\n",
    "                \n",
    "    def data(self, exclude=[]):\n",
    "        return self.model_data.drop(columns=exclude)\n",
    "        \n",
    "    def prepare(self, data, variables):\n",
    "        for var in variables:\n",
    "            self.prepared_variables.append(var.name)\n",
    "            self.model_data = pd.concat([self.model_data, self._prepare_variable(var, data)], axis=1)\n",
    "            \n",
    "    def create_interaction_with_nominal_variable(self, nominal_var, interaction_var, drop=True):\n",
    "        # Nominal variables have been one hot encoded (we need the list of the dummy variable names)\n",
    "        dummy_vars = [var for var in self.model_data.columns if nominal_var in var]\n",
    "        for var in dummy_vars:\n",
    "            self.model_data[var] = self.model_data[var] * self.model_data[interaction_var]\n",
    "        if drop:\n",
    "            self.model_data.drop(columns=[interaction_var], inplace=True)\n",
    "     \n",
    "    def merge_dummy_variables(self, variable1, variable2):\n",
    "        dummy_vars_1 = [var for var in self.model_data.columns if variable1 in var]\n",
    "        dummy_vars_2 = [var for var in self.model_data.columns if variable2 in var]\n",
    "        \n",
    "        for var in dummy_vars_2:\n",
    "            suffix = var.split('_')[1]\n",
    "            dummy = variable1 + '_' + suffix\n",
    "            self.model_data[dummy] = self.model_data.loc[:, [dummy, var]].max(axis=1)\n",
    "            self.model_data.drop(columns=[var], inplace=True)\n",
    "                \n",
    "    def normalize(self, exclude=[], method='z-score'):\n",
    "        for var in self.model_data.columns:\n",
    "            if var in exclude:\n",
    "                continue\n",
    "            if method == 'z-score':\n",
    "                self.model_data[var] = (self.model_data[var] - self.model_data[var].mean()) / self.model_data[var].std()\n",
    "            else:\n",
    "                self.model_data[var] = (self.model_data[var] - self.model_data[var].min()) / (self.model_data[var].max() - self.model_data[var].min())\n",
    "            \n",
    "    def normalize_include(self, include=[]):\n",
    "        for var_name in include:\n",
    "            dummy_vars = [var for var in self.model_data.columns if var_name in var]\n",
    "            for var in dummy_vars:\n",
    "                self.model_data[var] = (self.model_data[var] - self.model_data[var].mean()) / self.model_data[var].std()\n",
    "        \n",
    "    def _prepare_variable(self, variable, data):\n",
    "        if variable.type == VariableType.CONTINUOUS:\n",
    "            return self._prepare_continous_variable(variable, data)\n",
    "        elif variable.type == VariableType.DISCRETE:\n",
    "            return self._prepare_discrete_variable(variable, data) \n",
    "        elif variable.type == VariableType.ORDINAL:\n",
    "            return self._prepare_ordinal_variable(variable, data) \n",
    "        elif variable.type == VariableType.NOMINAL:\n",
    "            return self._prepare_nominal_variable(variable, data)\n",
    "        else:\n",
    "            print('Unknown Variable Type Error: ', variable.type) \n",
    "            \n",
    "    def _prepare_continous_variable(self, variable, data):\n",
    "        if variable.fn:\n",
    "            return variable.fn(data[variable.name])\n",
    "        return data[variable.name]\n",
    "    \n",
    "    def _prepare_discrete_variable(self, variable, data):\n",
    "        if variable.fn:\n",
    "            return variable.fn(data[variable.name])\n",
    "        return data[variable.name]\n",
    "    \n",
    "    def _prepare_ordinal_variable(self, variable, data):\n",
    "        if variable.mapping:\n",
    "            if variable.check_mapping(data[variable.name]):\n",
    "                return data[variable.name].map(variable.mapping)\n",
    "            else:\n",
    "                raise Exception(\"MappingError: Unable to encode the variable: {}\".format(variable))\n",
    "        return data[variable.name]\n",
    "            \n",
    "    def _prepare_nominal_variable(self, variable, data):\n",
    "        serie = data[variable.name]\n",
    "        if variable.mapping:\n",
    "            if variable.check_mapping(serie):\n",
    "                serie = serie.map(variable.mapping)\n",
    "            else:\n",
    "                raise Exception(\"MappingError: Unable to encode the variable: {}\".format(variable))\n",
    "        return pd.get_dummies(serie, prefix=variable.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ModelAgent Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ModelAgent` class is responsible to fit and evaluate our model. It manages automatically transformed target variables and compute the different evaluation metrics for the target and transformed target variables if we pass it the transformation inverse function.\n",
    "\n",
    "Using this class is easy:\n",
    "\n",
    "1. Instantiate a `ModelAgent` object by passing it:\n",
    "    * A model object like `HuberRegressor`, `LinearRegression`, `Ridge` and `Lasso` object\n",
    "    * The optional split parameters (default to test size 50% and random state 0)\n",
    "\n",
    "2. Call its `fit_and_evaluate()` method, passing:\n",
    "    * The prepared data returned by the `ModelDataFrameBuilder` object (`data()` method)\n",
    "    * The name of the target variable (as String)\n",
    "    * The transformation inverse function if the target variable has been transformed\n",
    "    \n",
    "3. Get the results attribute that is a dictionary containing the different vectors and matrices and the evaluation scores train/test x target/target transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelAgent:\n",
    "    def __init__(self, model, split_params={'test_size': 0.5, 'random_state': 0}):\n",
    "        self.model = model\n",
    "        self.split_params = split_params\n",
    "        self.coef_labels = None\n",
    "        self.results = None\n",
    "        \n",
    "    def fit_and_evaluate(self, data, target, inverse_fn=None):\n",
    "        \n",
    "        # prepare the predictors matrix and the target vector\n",
    "        X, y = self._prepare_matrix_vector(data, target)\n",
    "        \n",
    "        # split the train/test data sets\n",
    "        X_tr, X_te, y_tr, y_te = train_test_split(X, y, **self.split_params)\n",
    "        \n",
    "        # fit and evaluate the model\n",
    "        self._fit_and_evaluate(X_tr, X_te, y_tr, y_te, inverse_fn)\n",
    "     \n",
    "    def fit_and_evaluate_without_residuals(self, is_residual_filter, inverse_fn = None):\n",
    "        X_tr = self.results['data']['X_tr']\n",
    "        X_te = self.results['data']['X_te']\n",
    "        if inverse_fn:\n",
    "            # not elegant but to avoid re-intrance issue with the permutation of transformed target variable\n",
    "            y_tr = self.results['data']['y_transformed_tr']\n",
    "            y_te = self.results['data']['y_transformed_te']\n",
    "        else:\n",
    "            y_tr = self.results['data']['y_tr']\n",
    "            y_te = self.results['data']['y_te']\n",
    "        \n",
    "        X_tr_without_residuals = X_tr[~is_residual_filter, :]\n",
    "        y_tr_without_residuals = y_tr[~is_residual_filter]\n",
    "        self._fit_and_evaluate(X_tr_without_residuals, X_te, y_tr_without_residuals, y_te, inverse_fn)\n",
    "    \n",
    "    def predict(self, data, inverse_fn=None):\n",
    "        X = data.values\n",
    "        if inverse_fn:\n",
    "            return inverse_fn(self.model.predict(X))\n",
    "        else:\n",
    "            return self.model.predict(X)\n",
    "    \n",
    "    def coefs(self):\n",
    "        return pd.DataFrame({'label': self.coef_labels, 'coef': self.model.coef_ }) \\\n",
    "                     .sort_values(['coef'], ascending=True) \\\n",
    "                     .reset_index(drop=True)\n",
    "    \n",
    "    def print_coefs(self):\n",
    "        justify = self.coef_labels.map(len).max() + 1\n",
    "        \n",
    "        print(\"\\n\\nCoefficients:\")\n",
    "        print(\"-------------\")\n",
    "        print(\"{}: {: .4e}\".format(\"Intercept\".ljust(justify), self.model.intercept_))\n",
    "        for col, coef in zip(self.coef_labels, self.model.coef_):\n",
    "            print(\"{}: {: .4e}\".format(col.ljust(justify), coef))\n",
    "            \n",
    "    def plot_coefs(self, figsize=(10, 8), offset=0.002):\n",
    "        df_coefs = self.coefs()\n",
    "    \n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.barh(np.arange(0, df_coefs.shape[0]), df_coefs['coef'], tick_label=df_coefs['label'])\n",
    "        for index, value in enumerate(df_coefs['coef']):\n",
    "            if value > 0:\n",
    "                text_offset = offset * -1\n",
    "            else:\n",
    "                text_offset = 0.001\n",
    "            v = \"{: .4e}\".format(value)\n",
    "            plt.text(x=text_offset, y=index, s=v, va='center', color=blue, fontweight='bold')\n",
    "        plt.xlabel('Coefficients')\n",
    "        plt.show()\n",
    "        \n",
    "    def residuals_analysis(self, plot=False):\n",
    "        X_tr = self.results['data']['X_tr']\n",
    "        y_tr = self.results['data']['y_tr']\n",
    "        y_pred_tr = self.results['data']['y_pred_tr']\n",
    "        rss_tr = self.results['target']['train']['RSS']\n",
    "\n",
    "        # compute training residual standard error (RSE)\n",
    "        n_predictors = X_tr.shape[1]\n",
    "        rse = np.sqrt(rss_tr / (y_pred_tr.shape[0] - n_predictors - 1))\n",
    "\n",
    "        # compute high leverage statistics\n",
    "        H = np.matmul(X_tr, np.matmul(inv(np.matmul(X_tr.T, X_tr)), X_tr.T))  # H = X * (XT * X)^-1 * XT\n",
    "        leverage = np.diag(H) # leverage for the ith data point is the hii (diagonal factor) in the hat matrix\n",
    "        self.results['data']['leverage_log10'] = np.log10(leverage)\n",
    "        \n",
    "        # compute the studentized residual\n",
    "        studentized_residual_tr = (y_tr - y_pred_tr) / (rse * np.sqrt(1 - leverage))\n",
    "        self.results['data']['studentized_residual_tr'] = studentized_residual_tr\n",
    "        \n",
    "        if plot:\n",
    "            # plot the studentized residual in function of the fitted values and logarithm of the leverage score\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(16, 6), sharey=False)\n",
    "            ax[0].scatter(y_pred_tr, y_tr, s=5, color=blue)\n",
    "            ax[0].plot(y_pred_tr, y_pred_tr, color=red)\n",
    "            ax[0].set_xlabel('fitted value')\n",
    "            ax[0].set_ylabel('real value')\n",
    "            ax[1].scatter(y_pred_tr, studentized_residual_tr, s=5, color=blue)\n",
    "            ax[1].set_xlabel('fitted value')\n",
    "            ax[1].set_ylabel('studentized residual')\n",
    "            ax[2].scatter(np.log10(leverage), studentized_residual_tr, s=5, color=blue)\n",
    "            ax[2].set_xlabel('$\\log10{(leverage)}$')\n",
    "            plt.suptitle('Residual Analysis (train set)')\n",
    "            plt.show()\n",
    "        \n",
    "    def _prepare_matrix_vector(self, data, target):\n",
    "        self.coef_labels = data.drop(columns=[target]).columns\n",
    "        y = data[target].values\n",
    "        X = data.drop(columns=[target]).values\n",
    "        return (X, y)\n",
    "    \n",
    "    def _fit_and_evaluate(self, X_tr, X_te, y_tr, y_te, inverse_fn):\n",
    "        # fit the model\n",
    "        self.model.fit(X_tr, y_tr)\n",
    "        \n",
    "        # compute train/test predictions\n",
    "        y_pred_tr = self.model.predict(X_tr)\n",
    "        y_pred_te = self.model.predict(X_te) \n",
    "        \n",
    "        # The target variable could have been transformed\n",
    "        # Here, we apply the inverse transformation\n",
    "        # WARNING: for naming clarity, we permutte the variable names\n",
    "        y_transformed_pred_tr = y_pred_tr  # permutation\n",
    "        y_transformed_pred_te = y_pred_te  # permutation\n",
    "        if inverse_fn:\n",
    "            y_pred_tr = inverse_fn(y_transformed_pred_tr) \n",
    "            y_pred_te = inverse_fn(y_transformed_pred_te) \n",
    "        \n",
    "        # target values \n",
    "        y_transformed_tr = y_tr  # permutation\n",
    "        y_transformed_te = y_te  # permutation \n",
    "        if inverse_fn:\n",
    "            y_tr = inverse_fn(y_transformed_tr)\n",
    "            y_te = inverse_fn(y_transformed_te)\n",
    "        \n",
    "        # evaluate the model\n",
    "        self._evaluate(X_tr, X_te,\n",
    "                       y_tr, y_te, \n",
    "                       y_pred_tr, y_pred_te,\n",
    "                       y_transformed_tr, y_transformed_te,\n",
    "                       y_transformed_pred_tr, y_transformed_pred_te)\n",
    "                \n",
    "    def _evaluate(self, \n",
    "                  X_tr, X_te,\n",
    "                  y_tr, y_te, \n",
    "                  y_pred_tr, y_pred_te,\n",
    "                  y_transformed_tr, y_transformed_te,\n",
    "                  y_transformed_pred_tr, y_transformed_pred_te):\n",
    "        \n",
    "        self.results = {\n",
    "            'data': {\n",
    "                'X_tr': X_tr,\n",
    "                'X_te': X_te,\n",
    "                'y_tr': y_tr,\n",
    "                'y_pred_tr': y_pred_tr,\n",
    "                'y_te': y_te,\n",
    "                'y_pred_te': y_pred_te,\n",
    "                'y_transformed_tr': y_transformed_tr,\n",
    "                'y_transformed_te': y_transformed_te,\n",
    "                'y_transformed_pred_tr': y_transformed_pred_tr,\n",
    "                'y_transformed_pred_te': y_transformed_pred_te\n",
    "            },\n",
    "            'target': {\n",
    "                'train': {\n",
    "                    'RSS' : rss(y_tr, y_pred_tr),    \n",
    "                    'TSS' : tss(y_tr),\n",
    "                    'R2'  : r2score(y_tr, y_pred_tr),\n",
    "                    'MSE' : mse(y_tr, y_pred_tr),\n",
    "                    'RMSE': rmse(y_tr, y_pred_tr),\n",
    "                    'MAE' : mae(y_tr, y_pred_tr),\n",
    "                    'MSE Baseline': mse(y_tr, np.mean(y_tr)),\n",
    "                    'MAE Baseline': mae(y_tr, np.median(y_tr))\n",
    "                },\n",
    "                'test': {\n",
    "                    'RSS' : rss(y_te, y_pred_te),    \n",
    "                    'TSS' : tss(y_te),\n",
    "                    'R2'  : r2score(y_te, y_pred_te),\n",
    "                    'MSE' : mse(y_te, y_pred_te),\n",
    "                    'RMSE': rmse(y_te, y_pred_te),\n",
    "                    'MAE' : mae(y_te, y_pred_te),\n",
    "                    'MSE Baseline': mse(y_te, np.mean(y_tr)),\n",
    "                    'MAE Baseline': mae(y_te, np.median(y_tr))\n",
    "                }\n",
    "            },\n",
    "            'transformed_target': {\n",
    "                'train': {\n",
    "                    'RSS' : rss(y_transformed_tr, y_transformed_pred_tr),    \n",
    "                    'TSS' : tss(y_transformed_tr),\n",
    "                    'R2'  : r2score(y_transformed_tr, y_transformed_pred_tr),\n",
    "                    'MSE' : mse(y_transformed_tr, y_transformed_pred_tr),\n",
    "                    'RMSE': rmse(y_transformed_tr, y_transformed_pred_tr),\n",
    "                    'MAE' : mae(y_transformed_tr, y_transformed_pred_tr),\n",
    "                    'MSE Baseline': mse(y_transformed_tr, np.mean(y_transformed_tr)),\n",
    "                    'MAE Baseline': mae(y_transformed_tr, np.median(y_transformed_tr))    \n",
    "                },\n",
    "                'test': {\n",
    "                    'RSS' : rss(y_transformed_te, y_transformed_pred_te),    \n",
    "                    'TSS' : tss(y_transformed_te),\n",
    "                    'R2'  : r2score(y_transformed_te, y_transformed_pred_te),\n",
    "                    'MSE' : mse(y_transformed_te, y_transformed_pred_te),\n",
    "                    'RMSE': rmse(y_transformed_te, y_transformed_pred_te),\n",
    "                    'MAE' : mae(y_transformed_te, y_transformed_pred_te),\n",
    "                    'MSE Baseline': mse(y_transformed_te, np.mean(y_transformed_tr)),\n",
    "                    'MAE Baseline': mae(y_transformed_te, np.median(y_transformed_tr))\n",
    "                }\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util method to print model evaluation as stated in the tasks\n",
    "def print_scores(agent):\n",
    "    print('\\nTrain Set Scores:')\n",
    "    print('-----------------')\n",
    "    print('RMSLE Baseline :', np.round(np.sqrt(agent.results['transformed_target']['train']['MSE Baseline']), 6))\n",
    "    print('MAE Baseline :', np.round(agent.results['target']['train']['MAE Baseline'], 2))\n",
    "    print('')\n",
    "    print('RMSLE :', np.round(agent.results['transformed_target']['train']['RMSE'], 6))\n",
    "    print('MAE   :',np.round(agent.results['target']['train']['MAE'], 2))\n",
    "    print('R2    :', np.round(agent.results['target']['train']['R2'], 5))\n",
    "    print('')\n",
    "    print('Test Set Scores:')\n",
    "    print('----------------')\n",
    "    print('RMSLE Baseline :', np.round(np.sqrt(agent.results['transformed_target']['test']['MSE Baseline']), 6))\n",
    "    print('MAE Baseline :', np.round(agent.results['target']['test']['MAE Baseline'], 2))\n",
    "    print('')\n",
    "    print('RMSLE :', np.round(agent.results['transformed_target']['test']['RMSE'], 6))\n",
    "    print('MAE   :', np.round(agent.results['target']['test']['MAE'], 2))\n",
    "    print('R2    :', np.round(agent.results['target']['test']['R2'], 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `GridSearch` class is responsible to find the best hypermater for Ridge and Lasso Regularization. It allow also to plot the validation curves.\n",
    "\n",
    "Using this class is easy:\n",
    "\n",
    "1. Instantiate a GridSearch object by passing it:\n",
    "    * The prepared data\n",
    "    * The target variable name\n",
    "    * The inverse function if the target variable has been transformed\n",
    "    \n",
    "2. Call the `run()` method and pass:\n",
    "    * The list of hyper parameters to try\n",
    "    * The method 'Ridge'|'Lasso'\n",
    "    * The max_iter parameter if required\n",
    "\n",
    "3. Plot the validation curves by calling the `plot_validation_curves()` method\n",
    "4. Get the best hyper parameter by calling the `best_alpha()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridSearch:\n",
    "    \n",
    "    def __init__(self, data, target, inverse_fn=None):\n",
    "        self.df = data\n",
    "        self.target = target\n",
    "        self.inverse_fn = inverse_fn\n",
    "        self.train_scores = []\n",
    "        self.test_scores = []\n",
    "        \n",
    "    def run(self, alphas, method='Ridge', max_iter=None):\n",
    "        self.alphas = alphas\n",
    "        for alpha in self.alphas:\n",
    "            if method == 'Ridge':\n",
    "                model = Ridge(alpha, max_iter=max_iter)\n",
    "            else:\n",
    "                model = Lasso(alpha, max_iter=max_iter)\n",
    "                \n",
    "            ma = ModelAgent(model)\n",
    "            ma.fit_and_evaluate(self.df, self.target, self.inverse_fn)\n",
    "            \n",
    "            # Scores\n",
    "            if method == 'Ridge':\n",
    "                if self.inverse_fn:\n",
    "                    score_tr = ma.results['transformed_target']['train']['MSE']\n",
    "                    score_te = ma.results['transformed_target']['test']['MSE']\n",
    "                else:\n",
    "                    score_tr = ma.results['target']['train']['MSE']\n",
    "                    score_te = ma.results['target']['test']['MSE']\n",
    "            else:\n",
    "                score_tr = ma.results['target']['train']['MAE']\n",
    "                score_te = ma.results['target']['test']['MAE']\n",
    "            \n",
    "            self.train_scores.append(score_tr)\n",
    "            self.test_scores.append(score_te)\n",
    "            \n",
    "    def plot_validation_curves(self):\n",
    "        plt.semilogx(self.alphas, self.train_scores, label='train curve')\n",
    "        plt.semilogx(self.alphas, self.test_scores, label='test curve')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def best_alpha(self):\n",
    "        idx = np.argmin(self.test_scores)\n",
    "        return self.alphas[idx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
